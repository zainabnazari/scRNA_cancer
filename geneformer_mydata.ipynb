{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YYL6yvyT10HJ"
   },
   "source": [
    "# Environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "from scipy.io import mmread # For reading .mtx files\n",
    "from pathlib import Path # For better path handling\n",
    "\n",
    "# Geneformer specific imports\n",
    "import datasets\n",
    "from geneformer import DataCollatorForCellClassification\n",
    "from geneformer import EmbExtractor\n",
    "from geneformer import TranscriptomeTokenizer\n",
    "from transformers import BertForSequenceClassification, Trainer\n",
    "\n",
    "# PyTorch optimization\n",
    "from torch import set_float32_matmul_precision\n",
    "set_float32_matmul_precision('medium')\n",
    "\n",
    "print(\"--- Step 1: Define Data Paths and Download External Models ---\")\n",
    "\n",
    "# Define your raw data path\n",
    "raw_data_path = Path(\"/projects/bioinformatics/DB/IMMUCan/data_raw\")\n",
    "\n",
    "# --- Download and extract geneformer model (if not already local) ---\n",
    "print(\"Downloading and extracting Geneformer model...\")\n",
    "geneformer_model_url = 'https://www.dropbox.com/scl/fi/4edmbf7fik0q8kzyq2pef/fine_tuned_geneformer.tar.gz?rlkey=v0ux8v9a3qe8il6o7bowxep8c&st=6ar0ptjg&dl=0'\n",
    "!wget '{geneformer_model_url}' -O fine_tuned_geneformer.tar.gz\n",
    "!tar -xzf fine_tuned_geneformer.tar.gz\n",
    "\n",
    "# --- Download gene list (if not already local) ---\n",
    "print(\"Downloading gene list...\")\n",
    "gene_list_url = 'https://www.dropbox.com/scl/fi/brauikmesjfworl67cxov/cpdb_genelist.csv?rlkey=55ankib03njbf9tkci8tgzqc6&st=ezcv94sg&dl=0'\n",
    "!wget '{gene_list_url}' -O cpdb_genelist.csv\n",
    "\n",
    "print(\"\\n--- Step 2: Load Your Raw Data ---\")\n",
    "\n",
    "# Load the matrix\n",
    "# Ensure the path to matrix.mtx is correct relative to raw_data_path\n",
    "matrix = mmread(raw_data_path / 'matrix.mtx').tocsr()\n",
    "print(\"Original Matrix shape (genes x cells):\", matrix.shape) # Confirm this\n",
    "\n",
    "# Loading gene names and cell barcodes\n",
    "genes = pd.read_csv(raw_data_path / 'genes.tsv', sep='\\t', header=None)\n",
    "barcodes = pd.read_csv(raw_data_path / 'barcodes.tsv', sep='\\t', header=None)\n",
    "\n",
    "# --- CRITICAL FIX: Transpose the matrix to be (cells x genes) ---\n",
    "# Also, ensure that the number of rows in your 'barcodes' DataFrame\n",
    "# matches the number of COLUMNS in your original matrix (number of cells).\n",
    "# And the number of rows in your 'genes' DataFrame matches the number of ROWS\n",
    "# in your original matrix (number of genes).\n",
    "\n",
    "if matrix.shape[1] != len(barcodes):\n",
    "    raise ValueError(f\"Mismatch: Matrix has {matrix.shape[1]} columns (cells), but barcodes.tsv has {len(barcodes)} rows. Please check your data files.\")\n",
    "if matrix.shape[0] != len(genes):\n",
    "    raise ValueError(f\"Mismatch: Matrix has {matrix.shape[0]} rows (genes), but genes.tsv has {len(genes)} rows. Please check your data files.\")\n",
    "\n",
    "\n",
    "adata = sc.AnnData(matrix.T, # <<< --- THE FIX IS HERE: .T for transpose\n",
    "                   obs=pd.DataFrame(index=barcodes[0].values),\n",
    "                   var=pd.DataFrame(index=genes[0].values))\n",
    "\n",
    "# Add gene symbols if available (assuming they are in the second column of genes.tsv)\n",
    "if len(genes.columns) > 1:\n",
    "    adata.var['gene_symbol'] = genes[1].values\n",
    "\n",
    "adata.var[\"ensembl_id\"] = adata.var.index # Keep Ensembl IDs as a separate column\n",
    "\n",
    "# Add basic QC metrics and joinid\n",
    "adata.obs[\"n_counts\"] = adata.X.sum(axis=1)\n",
    "adata.obs[\"joinid\"] = list(range(adata.n_obs))\n",
    "\n",
    "print(f\"AnnData object created with shape (cells x genes): {adata.shape}\")\n",
    "print(\"AnnData .obs head:\")\n",
    "print(adata.obs.head())\n",
    "print(\"\\nAnnData .var head:\")\n",
    "print(adata.var.head())\n",
    "\n",
    "print(\"\\n--- Step 3: Save AnnData and Tokenize Data for Geneformer ---\")\n",
    "\n",
    "h5ad_dir = \"./data/h5ad/\" # Use a relative path for output in your current working directory\n",
    "\n",
    "if not os.path.exists(h5ad_dir):\n",
    "    os.makedirs(h5ad_dir)\n",
    "\n",
    "adata.write(h5ad_dir + \"my_immu_can_data.h5ad\")\n",
    "print(f\"AnnData saved to {h5ad_dir}my_immu_can_data.h5ad\")\n",
    "\n",
    "token_dir = \"data/tokenized_data/\" # Use a relative path for output\n",
    "\n",
    "if not os.path.exists(token_dir):\n",
    "    os.makedirs(token_dir)\n",
    "\n",
    "tokenizer = TranscriptomeTokenizer(custom_attr_name_dict={\"joinid\": \"joinid\"})\n",
    "print(f\"Tokenizing data from {h5ad_dir} to {token_dir}...\")\n",
    "tokenizer.tokenize_data(\n",
    "    data_directory=h5ad_dir,\n",
    "    output_directory=token_dir,\n",
    "    output_prefix=\"my_immu_can\", # Use a unique prefix for your data\n",
    "    file_format=\"h5ad\",\n",
    ")\n",
    "print(\"Data tokenization complete.\")\n",
    "\n",
    "\n",
    "print(\"\\n--- Step 4: Load Geneformer Model and Make Predictions ---\")\n",
    "\n",
    "model_dir = \"./fine_tuned_geneformer/\" # Path where the downloaded model was extracted\n",
    "label_mapping_dict_file = os.path.join(model_dir, \"label_to_cell_subclass.json\")\n",
    "\n",
    "# Ensure the label mapping file exists in your downloaded model\n",
    "if not os.path.exists(label_mapping_dict_file):\n",
    "    raise FileNotFoundError(f\"Label mapping file not found: {label_mapping_dict_file}. \"\n",
    "                            \"Please ensure the Geneformer model was extracted correctly \"\n",
    "                            \"and contains this file.\")\n",
    "\n",
    "with open(label_mapping_dict_file) as fp:\n",
    "    label_mapping_dict = json.load(fp)\n",
    "\n",
    "print(\"First 5 entries of label mapping:\")\n",
    "for k in list(label_mapping_dict.keys())[:5]:\n",
    "    print(k, ': ', label_mapping_dict[k])\n",
    "\n",
    "dataset = datasets.load_from_disk(token_dir + \"my_immu_can.dataset\") # Load your tokenized data\n",
    "print(f\"Loaded tokenized dataset with {len(dataset)} cells.\")\n",
    "\n",
    "# Add dummy label column for prediction, as Geneformer's trainer expects it\n",
    "dataset = dataset.add_column(\"label\", [0] * len(dataset))\n",
    "\n",
    "# Reload the fine-tuned Geneformer model\n",
    "print(\"Loading fine-tuned Geneformer model...\")\n",
    "model = BertForSequenceClassification.from_pretrained(model_dir)\n",
    "\n",
    "# Create the trainer for prediction\n",
    "trainer = Trainer(model=model, data_collator=DataCollatorForCellClassification())\n",
    "\n",
    "# Use trainer to make predictions\n",
    "print(\"Making predictions with Geneformer...\")\n",
    "predictions = trainer.predict(dataset)\n",
    "print(\"Predictions complete.\")\n",
    "\n",
    "# Process predictions\n",
    "predicted_label_ids = np.argmax(predictions.predictions, axis=1)\n",
    "predicted_logits = [predictions.predictions[i][predicted_label_ids[i]] for i in range(len(predicted_label_ids))]\n",
    "predicted_labels = [label_mapping_dict[str(i)] for i in predicted_label_ids]\n",
    "\n",
    "# Add predictions to AnnData object\n",
    "adata.obs[\"predicted_cell_subclass\"] = predicted_labels\n",
    "# Using sigmoid for probability-like score (for a single predicted class's logit)\n",
    "adata.obs[\"predicted_cell_subclass_probability\"] = 1 / (1 + np.exp(-np.array(predicted_logits)))\n",
    "\n",
    "print(\"\\n--- Step 5: Standard Single-Cell Data Preprocessing and Analysis (Scanpy) ---\")\n",
    "\n",
    "# These steps are standard for scRNA-seq analysis before visualization\n",
    "sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "sc.pp.log1p(adata)\n",
    "sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5)\n",
    "\n",
    "# Ensure highly_variable is True before subsetting\n",
    "if np.sum(adata.var['highly_variable']) > 0:\n",
    "    adata = adata[:, adata.var.highly_variable]\n",
    "    print(f\"Subsetted to {adata.shape[1]} highly variable genes.\")\n",
    "else:\n",
    "    print(\"No highly variable genes found with current parameters. Skipping subsetting.\")\n",
    "\n",
    "sc.pp.scale(adata, max_value=10)\n",
    "sc.tl.pca(adata, svd_solver=\"arpack\")\n",
    "sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40) # Adjust n_pcs if your data is very different\n",
    "sc.tl.umap(adata)\n",
    "\n",
    "print(\"Running Leiden clustering...\")\n",
    "sc.tl.leiden(adata)\n",
    "\n",
    "print(\"Scanpy preprocessing and dimensionality reduction complete.\")\n",
    "\n",
    "print(\"\\n--- Step 6: Visualize Results ---\")\n",
    "\n",
    "print(\"Generating UMAP plots...\")\n",
    "# Plot UMAP colored by Leiden clusters (your new \"original\" clusters)\n",
    "sc.pl.umap(adata, color=\"leiden\", title=\"Leiden Clustering of IMMUCan Data\", show=False, save=\"_leiden.png\")\n",
    "\n",
    "# Plot UMAP colored by Geneformer predicted cell types and their probabilities\n",
    "sc.pl.umap(\n",
    "    adata,\n",
    "    color=[\"predicted_cell_subclass_probability\", \"predicted_cell_subclass\"],\n",
    "    title=\"Predicted Geneformer Annotations for IMMUCan Data\",\n",
    "    show=False, save=\"_geneformer_predictions.png\"\n",
    ")\n",
    "\n",
    "# Plot both side-by-side for comparison\n",
    "sc.pl.umap(\n",
    "    adata,\n",
    "    color=[\"leiden\", \"predicted_cell_subclass\"],\n",
    "    legend_loc = 'on data',\n",
    "    title=\"Comparison: Leiden vs. Geneformer (IMMUCan Data)\",\n",
    "    show=True, save=\"_comparison.png\"\n",
    ")\n",
    "\n",
    "print(\"Analysis complete. UMAP plots saved as PNG files in your current directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "from scipy.io import mmread # For reading .mtx files\n",
    "from pathlib import Path # For better path handling\n",
    "\n",
    "# Geneformer specific imports\n",
    "import datasets\n",
    "from geneformer import DataCollatorForCellClassification\n",
    "from geneformer import EmbExtractor\n",
    "from geneformer import TranscriptomeTokenizer\n",
    "from transformers import BertForSequenceClassification, Trainer\n",
    "\n",
    "# PyTorch optimization\n",
    "from torch import set_float32_matmul_precision\n",
    "set_float32_matmul_precision('medium')\n",
    "\n",
    "print(\"--- Step 1: Define Data Paths and Download External Models ---\")\n",
    "\n",
    "# Define your raw data path\n",
    "raw_data_path = Path(\"/projects/bioinformatics/DB/IMMUCan/data_raw\")\n",
    "\n",
    "# --- Download and extract geneformer model (if not already local) ---\n",
    "print(\"Downloading and extracting Geneformer model...\")\n",
    "geneformer_model_url = 'https://www.dropbox.com/scl/fi/4edmbf7fik0q8kzyq2pef/fine_tuned_geneformer.tar.gz?rlkey=v0ux8v9a3qe8il6o7bowxep8c&st=6ar0ptjg&dl=0'\n",
    "if not os.path.exists(\"./fine_tuned_geneformer\"):\n",
    "    !wget '{geneformer_model_url}' -O fine_tuned_geneformer.tar.gz\n",
    "    !tar -xzf fine_tuned_geneformer.tar.gz\n",
    "else:\n",
    "    print(\"Geneformer model directory already exists, skipping download/extract.\")\n",
    "\n",
    "\n",
    "# --- Download gene list (if not already local) ---\n",
    "print(\"Downloading gene list...\")\n",
    "gene_list_url = 'https://www.dropbox.com/scl/fi/brauikmesjfworl67cxov/cpdb_genelist.csv?rlkey=55ankib03njbf9tkci8tgzqc6&st=ezcv94sg&dl=0'\n",
    "if not os.path.exists(\"cpdb_genelist.csv\"):\n",
    "    !wget '{gene_list_url}' -O cpdb_genelist.csv\n",
    "else:\n",
    "    print(\"cpdb_genelist.csv already exists, skipping download.\")\n",
    "\n",
    "print(\"\\n--- Step 2: Load Your Raw Data ---\")\n",
    "\n",
    "# Load the matrix\n",
    "matrix = mmread(raw_data_path / 'matrix.mtx').tocsr()\n",
    "print(\"Original Matrix shape (genes x cells):\", matrix.shape)\n",
    "\n",
    "# Loading gene names and cell barcodes\n",
    "genes = pd.read_csv(raw_data_path / 'genes.tsv', sep='\\t', header=None)\n",
    "barcodes = pd.read_csv(raw_data_path / 'barcodes.tsv', sep='\\t', header=None)\n",
    "\n",
    "# --- CRITICAL FIXES FOR AnnData CREATION ---\n",
    "\n",
    "if matrix.shape[1] != len(barcodes):\n",
    "    raise ValueError(f\"Mismatch: Matrix has {matrix.shape[1]} columns (cells), but barcodes.tsv has {len(barcodes)} rows. Please check your data files.\")\n",
    "if matrix.shape[0] != len(genes):\n",
    "    raise ValueError(f\"Mismatch: Matrix has {matrix.shape[0]} rows (genes), but genes.tsv has {len(genes)} rows. Please check your data files.\")\n",
    "\n",
    "# Create the var DataFrame explicitly first, ensuring 'ensembl_id' column is there\n",
    "var_df = pd.DataFrame(index=genes[0].values)\n",
    "var_df['ensembl_id'] = genes[0].values\n",
    "\n",
    "if len(genes.columns) > 1:\n",
    "    var_df['gene_symbol'] = genes[1].values\n",
    "else:\n",
    "    print(\"Warning: genes.tsv only has one column. 'gene_symbol' will not be set.\")\n",
    "\n",
    "adata = sc.AnnData(matrix.T, # Transpose the matrix\n",
    "                   obs=pd.DataFrame(index=barcodes[0].values), # Cell barcodes as obs index\n",
    "                   var=var_df) # Use the carefully constructed var_df\n",
    "\n",
    "# --- FIX for n_counts access: Ensure it's explicitly a Series and check before save ---\n",
    "adata.obs[\"n_counts\"] = pd.Series(adata.X.sum(axis=1).A.flatten(), index=adata.obs.index) # .A.flatten() for sparse matrix sum\n",
    "adata.obs[\"joinid\"] = list(range(adata.n_obs))\n",
    "\n",
    "\n",
    "print(\"\\n--- DEBUGGING: Check adata.var and adata.obs structure before tokenization ---\")\n",
    "print(\"adata.var columns:\", adata.var.columns.tolist())\n",
    "print(\"adata.var head:\")\n",
    "print(adata.var.head())\n",
    "if 'ensembl_id' in adata.var.columns:\n",
    "    print(\"\\nFirst 5 ensembl_ids in adata.var['ensembl_id']:\")\n",
    "    print(adata.var['ensembl_id'].head().tolist())\n",
    "else:\n",
    "    print(\"\\nERROR: 'ensembl_id' column is NOT in adata.var. Geneformer cannot proceed.\")\n",
    "    raise KeyError(\"'ensembl_id' column is missing from adata.var. Geneformer cannot proceed.\")\n",
    "\n",
    "print(f\"Data type of adata.var['ensembl_id']: {adata.var['ensembl_id'].dtype}\")\n",
    "\n",
    "print(\"\\nadata.obs columns:\", adata.obs.columns.tolist())\n",
    "print(\"adata.obs head:\")\n",
    "print(adata.obs.head())\n",
    "if 'n_counts' in adata.obs.columns:\n",
    "    print(\"\\nFirst 5 n_counts in adata.obs['n_counts']:\")\n",
    "    print(adata.obs['n_counts'].head().tolist())\n",
    "else:\n",
    "    print(\"\\nERROR: 'n_counts' column is NOT in adata.obs. Geneformer cannot proceed.\")\n",
    "    raise KeyError(\"'n_counts' column is missing from adata.obs. Geneformer cannot proceed.\")\n",
    "\n",
    "print(f\"Data type of adata.obs['n_counts']: {adata.obs['n_counts'].dtype}\")\n",
    "\n",
    "\n",
    "print(f\"AnnData object created with shape (cells x genes): {adata.shape}\")\n",
    "\n",
    "\n",
    "print(\"\\n--- Step 3: Save AnnData and Tokenize Data for Geneformer ---\")\n",
    "\n",
    "h5ad_dir = \"./data/h5ad/\"\n",
    "token_dir = \"data/tokenized_data/\"\n",
    "\n",
    "if os.path.exists(h5ad_dir):\n",
    "    print(f\"Clearing contents of {h5ad_dir} to avoid tokenizing old files...\")\n",
    "    for f in os.listdir(h5ad_dir):\n",
    "        os.remove(os.path.join(h5ad_dir, f))\n",
    "else:\n",
    "    os.makedirs(h5ad_dir)\n",
    "\n",
    "if not os.path.exists(token_dir):\n",
    "    os.makedirs(token_dir)\n",
    "\n",
    "\n",
    "adata.write(h5ad_dir + \"my_immu_can_data.h5ad\")\n",
    "print(f\"AnnData saved to {h5ad_dir}my_immu_can_data.h5ad\")\n",
    "\n",
    "tokenizer = TranscriptomeTokenizer(custom_attr_name_dict={\"joinid\": \"joinid\"})\n",
    "print(f\"Tokenizing data from {h5ad_dir} (specifically, 'my_immu_can_data.h5ad')...\")\n",
    "\n",
    "tokenizer.tokenize_data(\n",
    "    data_directory=h5ad_dir,\n",
    "    output_directory=token_dir,\n",
    "    output_prefix=\"my_immu_can\",\n",
    "    file_format=\"h5ad\",\n",
    ")\n",
    "print(\"Data tokenization complete.\")\n",
    "\n",
    "\n",
    "print(\"\\n--- Step 4: Load Geneformer Model and Make Predictions ---\")\n",
    "\n",
    "model_dir = \"./fine_tuned_geneformer/\"\n",
    "label_mapping_dict_file = os.path.join(model_dir, \"label_to_cell_subclass.json\")\n",
    "\n",
    "if not os.path.exists(label_mapping_dict_file):\n",
    "    raise FileNotFoundError(f\"Label mapping file not found: {label_mapping_dict_file}. \"\n",
    "                            \"Please ensure the Geneformer model was extracted correctly \"\n",
    "                            \"and contains this file.\")\n",
    "\n",
    "with open(label_mapping_dict_file) as fp:\n",
    "    label_mapping_dict = json.load(fp)\n",
    "\n",
    "print(\"First 5 entries of label mapping:\")\n",
    "for k in list(label_mapping_dict.keys())[:5]:\n",
    "    print(k, ': ', label_mapping_dict[k])\n",
    "\n",
    "dataset = datasets.load_from_disk(token_dir + \"my_immu_can.dataset\")\n",
    "print(f\"Loaded tokenized dataset with {len(dataset)} cells.\")\n",
    "\n",
    "dataset = dataset.add_column(\"label\", [0] * len(dataset))\n",
    "\n",
    "print(\"Loading fine-tuned Geneformer model...\")\n",
    "model = BertForSequenceClassification.from_pretrained(model_dir)\n",
    "\n",
    "trainer = Trainer(model=model, data_collator=DataCollatorForCellClassification())\n",
    "\n",
    "print(\"Making predictions with Geneformer...\")\n",
    "predictions = trainer.predict(dataset)\n",
    "print(\"Predictions complete.\")\n",
    "\n",
    "predicted_label_ids = np.argmax(predictions.predictions, axis=1)\n",
    "predicted_logits = [predictions.predictions[i][predicted_label_ids[i]] for i in range(len(predicted_label_ids))]\n",
    "predicted_labels = [label_mapping_dict[str(i)] for i in predicted_label_ids]\n",
    "\n",
    "adata.obs[\"predicted_cell_subclass\"] = predicted_labels\n",
    "adata.obs[\"predicted_cell_subclass_probability\"] = 1 / (1 + np.exp(-np.array(predicted_logits)))\n",
    "\n",
    "print(\"\\n--- Step 5: Standard Single-Cell Data Preprocessing and Analysis (Scanpy) ---\")\n",
    "\n",
    "sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "sc.pp.log1p(adata)\n",
    "sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5)\n",
    "\n",
    "if np.sum(adata.var['highly_variable']) > 0:\n",
    "    adata = adata[:, adata.var.highly_variable]\n",
    "    print(f\"Subsetted to {adata.shape[1]} highly variable genes.\")\n",
    "else:\n",
    "    print(\"No highly variable genes found with current parameters. Skipping subsetting.\")\n",
    "\n",
    "sc.pp.scale(adata, max_value=10)\n",
    "sc.tl.pca(adata, svd_solver=\"arpack\")\n",
    "sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40)\n",
    "sc.tl.umap(adata)\n",
    "\n",
    "print(\"Running Leiden clustering...\")\n",
    "sc.tl.leiden(adata)\n",
    "\n",
    "print(\"Scanpy preprocessing and dimensionality reduction complete.\")\n",
    "\n",
    "print(\"\\n--- Step 6: Visualize Results ---\")\n",
    "\n",
    "print(\"Generating UMAP plots...\")\n",
    "sc.pl.umap(adata, color=\"leiden\", title=\"Leiden Clustering of IMMUCan Data\", show=False, save=\"_leiden.png\")\n",
    "\n",
    "sc.pl.umap(\n",
    "    adata,\n",
    "    color=[\"predicted_cell_subclass_probability\", \"predicted_cell_subclass\"],\n",
    "    title=\"Predicted Geneformer Annotations for IMMUCan Data\",\n",
    "    show=False, save=\"_geneformer_predictions.png\"\n",
    ")\n",
    "\n",
    "sc.pl.umap(\n",
    "    adata,\n",
    "    color=[\"leiden\", \"predicted_cell_subclass\"],\n",
    "    legend_loc = 'on data',\n",
    "    title=\"Comparison: Leiden vs. Geneformer (IMMUCan Data)\",\n",
    "    show=True, save=\"_comparison.png\"\n",
    ")\n",
    "\n",
    "print(\"Analysis complete. UMAP plots saved as PNG files in your current directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bVUPSGqd10HN"
   },
   "source": [
    "# Models download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FZz_wUcC10HN"
   },
   "source": [
    "Models hosted on https://cellxgene.cziscience.com/census-models normally require Amazon Web Services (AWS) to download. Since aws-cli is not installed on google colab I have temporarily loaded them to dropbox.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B4hEBlDF10HO"
   },
   "outputs": [],
   "source": [
    "# Download and extract geneformer model\n",
    "!wget 'https://www.dropbox.com/scl/fi/4edmbf7fik0q8kzyq2pef/fine_tuned_geneformer.tar.gz?rlkey=v0ux8v9a3qe8il6o7bowxep8c&st=6ar0ptjg&dl=0' -O fine_tuned_geneformer.tar.gz\n",
    "!tar -xzf fine_tuned_geneformer.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H4pCJM_u10HP"
   },
   "outputs": [],
   "source": [
    "!ls fine_tuned_geneformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fM7jRh0k10HP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ava4FN2E10HQ"
   },
   "source": [
    "# Data download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qM8IJ4NdJOZ3"
   },
   "outputs": [],
   "source": [
    "\n",
    "!mkdir -p data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nNyxVDxoJOZ2"
   },
   "source": [
    "# Geneformer for cell class prediction and data projection\n",
    "\n",
    "This notebook provides examples to utilize the CELLxGENE collaboration fine-tuned Geneformer model with user data. For more information on the model please refer to the [Census model page](https://cellxgene.cziscience.com/census-models).\n",
    "\n",
    "**IMPORTANT:** This tutorial requires cellxgene-census package version 1.9.1 or later.\n",
    "\n",
    "**Contents**\n",
    "\n",
    "1. Requirements.\n",
    "1. Preparing data and model.\n",
    "1. Using the Geneformer fine-tuned model for **cell subclass inference**.\n",
    "1. Using the Geneformer fine-tuned model for **data projection**.\n",
    "\n",
    "> ⚠️ Note \"cell subclass\" is a high-level grouping of cell types as annotated in CELLxGENE Discover via the CL ontology see [https://cellxgene.cziscience.com/collections](https://cellxgene.cziscience.com/collections\n",
    "\n",
    "> ⚠️ Note that the Census RNA data includes duplicate cells present across multiple datasets. Duplicate cells can be filtered in or out using the cell metadata variable `is_primary_data` which is described in the [Census schema](https://github.com/chanzuckerberg/cellxgene-census/blob/main/docs/cellxgene_census_schema.md#repeated-data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WMSPZD89JOZ4"
   },
   "source": [
    "### Downloading the fine-tuned Geneformer model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MlFHb6ieJOZ6"
   },
   "source": [
    "### Importing required packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sRjXhfCUJOZ8"
   },
   "source": [
    "Finally all the required packages are loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iquZrJXvJOZ8"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "#import cellxgene_census\n",
    "import datasets\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "from geneformer import DataCollatorForCellClassification\n",
    "from geneformer import EmbExtractor\n",
    "from geneformer import TranscriptomeTokenizer\n",
    "from transformers import BertForSequenceClassification, Trainer\n",
    "\n",
    "from torch import set_float32_matmul_precision\n",
    "set_float32_matmul_precision('medium')\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from scipy.io import mmread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5UoH9ElJOZ8"
   },
   "source": [
    "## Preparing data and model\n",
    "\n",
    "### Preparing single-cell data\n",
    "\n",
    "Let's load the test data. In preparation to use with Geneformer we do the following:\n",
    "\n",
    "- Set the index as the ENSEMBL gene ID and stores it in the `obs` column `\"ensembl_id\"`\n",
    "  - e.g. `ENSG00000139618` (*without* a version number suffix)\n",
    "- Add read counts to the `obs` column `\"n_counts\"`\n",
    "- Add an ID column to be used for joining later in the  `obs` column `\"joinid\"`\n",
    "\n",
    "Then we write the resulting H5AD file to disk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0qf57Mf-JOZ8"
   },
   "source": [
    "Now we can tokenize the test data using Geneformer's tokenizer, while keeping track of `\"joinid\"` for future joining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import json\n",
    "import os\n",
    "import shutil # Import shutil for rmtree\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "from scipy.io import mmread # For reading .mtx files\n",
    "from pathlib import Path # For better path handling\n",
    "\n",
    "# Geneformer specific imports\n",
    "import datasets\n",
    "from geneformer import DataCollatorForCellClassification\n",
    "from geneformer import EmbExtractor\n",
    "from geneformer import TranscriptomeTokenizer\n",
    "from transformers import BertForSequenceClassification, Trainer\n",
    "\n",
    "# PyTorch optimization\n",
    "from torch import set_float32_matmul_precision\n",
    "set_float32_matmul_precision('medium')\n",
    "\n",
    "print(\"--- Step 1: Define Data Paths and Download External Models ---\")\n",
    "\n",
    "# Define your raw data path\n",
    "raw_data_path = Path(\"/projects/bioinformatics/DB/IMMUCan/data_raw\")\n",
    "\n",
    "# --- Download and extract geneformer model (if not already local) ---\n",
    "print(\"Downloading and extracting Geneformer model...\")\n",
    "geneformer_model_url = 'https://www.dropbox.com/scl/fi/4edmbf7fik0q8kzyq2pef/fine_tuned_geneformer.tar.gz?rlkey=v0ux8v9a3qe8il6o7bowxep8c&st=6ar0ptjg&dl=0'\n",
    "if not os.path.exists(\"./fine_tuned_geneformer\"):\n",
    "    !wget '{geneformer_model_url}' -O fine_tuned_geneformer.tar.gz\n",
    "    !tar -xzf fine_tuned_geneformer.tar.gz\n",
    "else:\n",
    "    print(\"Geneformer model directory already exists, skipping download/extract.\")\n",
    "\n",
    "\n",
    "# --- Download gene list (if not already local) ---\n",
    "print(\"Downloading gene list...\")\n",
    "gene_list_url = 'https://www.dropbox.com/scl/fi/brauikmesjfworl67cxov/cpdb_genelist.csv?rlkey=55ankib03njbf9tkci8tgzqc6&st=ezcv94sg&dl=0'\n",
    "if not os.path.exists(\"cpdb_genelist.csv\"):\n",
    "    !wget '{gene_list_url}' -O cpdb_genelist.csv\n",
    "else:\n",
    "    print(\"cpdb_genelist.csv already exists, skipping download.\")\n",
    "\n",
    "print(\"\\n--- Step 2: Load Your Raw Data ---\")\n",
    "\n",
    "# Load the matrix\n",
    "matrix = mmread(raw_data_path / 'matrix.mtx').tocsr()\n",
    "print(\"Original Matrix shape (genes x cells):\", matrix.shape)\n",
    "\n",
    "# Loading gene names and cell barcodes\n",
    "genes = pd.read_csv(raw_data_path / 'genes.tsv', sep='\\t', header=None)\n",
    "barcodes = pd.read_csv(raw_data_path / 'barcodes.tsv', sep='\\t', header=None)\n",
    "\n",
    "# --- CRITICAL FIXES FOR AnnData CREATION ---\n",
    "\n",
    "if matrix.shape[1] != len(barcodes):\n",
    "    raise ValueError(f\"Mismatch: Matrix has {matrix.shape[1]} columns (cells), but barcodes.tsv has {len(barcodes)} rows. Please check your data files.\")\n",
    "if matrix.shape[0] != len(genes):\n",
    "    raise ValueError(f\"Mismatch: Matrix has {matrix.shape[0]} rows (genes), but genes.tsv has {len(genes)} rows. Please check your data files.\")\n",
    "\n",
    "# Create the var DataFrame explicitly first, ensuring 'ensembl_id' column is there\n",
    "var_df = pd.DataFrame(index=genes[0].values)\n",
    "var_df['ensembl_id'] = genes[0].values\n",
    "\n",
    "if len(genes.columns) > 1:\n",
    "    var_df['gene_symbol'] = genes[1].values\n",
    "else:\n",
    "    print(\"Warning: genes.tsv only has one column. 'gene_symbol' will not be set.\")\n",
    "\n",
    "adata = sc.AnnData(matrix.T, # Transpose the matrix\n",
    "                   obs=pd.DataFrame(index=barcodes[0].values), # Cell barcodes as obs index\n",
    "                   var=var_df) # Use the carefully constructed var_df\n",
    "\n",
    "# --- FIX for n_counts access: Ensure it's explicitly a Series and check before save ---\n",
    "adata.obs[\"n_counts\"] = pd.Series(adata.X.sum(axis=1).A.flatten(), index=adata.obs.index) # .A.flatten() for sparse matrix sum\n",
    "adata.obs[\"joinid\"] = list(range(adata.n_obs))\n",
    "\n",
    "\n",
    "print(\"\\n--- DEBUGGING: Check adata.var and adata.obs structure before tokenization ---\")\n",
    "print(\"adata.var columns:\", adata.var.columns.tolist())\n",
    "print(\"adata.var head:\")\n",
    "print(adata.var.head())\n",
    "if 'ensembl_id' in adata.var.columns:\n",
    "    print(\"\\nFirst 5 ensembl_ids in adata.var['ensembl_id']:\")\n",
    "    print(adata.var['ensembl_id'].head().tolist())\n",
    "else:\n",
    "    print(\"\\nERROR: 'ensembl_id' column is NOT in adata.var. Geneformer cannot proceed.\")\n",
    "    raise KeyError(\"'ensembl_id' column is missing from adata.var. Geneformer cannot proceed.\")\n",
    "\n",
    "print(f\"Data type of adata.var['ensembl_id']: {adata.var['ensembl_id'].dtype}\")\n",
    "\n",
    "print(\"\\nadata.obs columns:\", adata.obs.columns.tolist())\n",
    "print(\"adata.obs head:\")\n",
    "print(adata.obs.head())\n",
    "if 'n_counts' in adata.obs.columns:\n",
    "    print(\"\\nFirst 5 n_counts in adata.obs['n_counts']:\")\n",
    "    print(adata.obs['n_counts'].head().tolist())\n",
    "else:\n",
    "    print(\"\\nERROR: 'n_counts' column is NOT in adata.obs. Geneformer cannot proceed.\")\n",
    "    raise KeyError(\"'n_counts' column is missing from adata.obs. Geneformer cannot proceed.\")\n",
    "\n",
    "print(f\"Data type of adata.obs['n_counts']: {adata.obs['n_counts'].dtype}\")\n",
    "\n",
    "\n",
    "print(f\"AnnData object created with shape (cells x genes): {adata.shape}\")\n",
    "\n",
    "\n",
    "print(\"\\n--- Step 3: Save AnnData and Tokenize Data for Geneformer ---\")\n",
    "\n",
    "h5ad_dir = \"./data/h5ad/\"\n",
    "token_dir = \"data/tokenized_data/\"\n",
    "\n",
    "# --- MODIFIED: Use shutil.rmtree for more robust directory cleanup ---\n",
    "if os.path.exists(h5ad_dir):\n",
    "    print(f\"Attempting to clear contents of {h5ad_dir} using shutil.rmtree...\")\n",
    "    try:\n",
    "        shutil.rmtree(h5ad_dir)\n",
    "        print(f\"Successfully cleared {h5ad_dir}.\")\n",
    "    except OSError as e:\n",
    "        print(f\"WARNING: Could not clear {h5ad_dir} due to an OS error: {e}\")\n",
    "        print(\"This is often caused by lingering file locks, especially on network drives (NFS).\")\n",
    "        print(\"Please try:\")\n",
    "        print(\"  1. Restarting your Python kernel/session.\")\n",
    "        print(f\"  2. Manually deleting the '{h5ad_dir}' directory from your terminal.\")\n",
    "        print(\"     Example: `rm -rf ./data/h5ad` (from the directory where your script is running)\")\n",
    "        print(\"Exiting script as a clean state is required for tokenization.\")\n",
    "        exit() # Exit the script if cleanup fails\n",
    "os.makedirs(h5ad_dir) # Recreate the directory after successful removal\n",
    "\n",
    "if not os.path.exists(token_dir):\n",
    "    os.makedirs(token_dir)\n",
    "\n",
    "\n",
    "adata.write(h5ad_dir + \"my_immu_can_data.h5ad\")\n",
    "print(f\"AnnData saved to {h5ad_dir}my_immu_can_data.h5ad\")\n",
    "\n",
    "tokenizer = TranscriptomeTokenizer(custom_attr_name_dict={\"joinid\": \"joinid\"})\n",
    "print(f\"Tokenizing data from {h5ad_dir} (specifically, 'my_immu_can_data.h5ad')...\")\n",
    "\n",
    "tokenizer.tokenize_data(\n",
    "    data_directory=h5ad_dir,\n",
    "    output_directory=token_dir,\n",
    "    output_prefix=\"my_immu_can\",\n",
    "    file_format=\"h5ad\",\n",
    ")\n",
    "print(\"Data tokenization complete.\")\n",
    "\n",
    "\n",
    "print(\"\\n--- Step 4: Load Geneformer Model and Make Predictions ---\")\n",
    "\n",
    "model_dir = \"./fine_tuned_geneformer/\"\n",
    "label_mapping_dict_file = os.path.join(model_dir, \"label_to_cell_subclass.json\")\n",
    "\n",
    "if not os.path.exists(label_mapping_dict_file):\n",
    "    raise FileNotFoundError(f\"Label mapping file not found: {label_mapping_dict_file}. \"\n",
    "                            \"Please ensure the Geneformer model was extracted correctly \"\n",
    "                            \"and contains this file.\")\n",
    "\n",
    "with open(label_mapping_dict_file) as fp:\n",
    "    label_mapping_dict = json.load(fp)\n",
    "\n",
    "print(\"First 5 entries of label mapping:\")\n",
    "for k in list(label_mapping_dict.keys())[:5]:\n",
    "    print(k, ': ', label_mapping_dict[k])\n",
    "\n",
    "dataset = datasets.load_from_disk(token_dir + \"my_immu_can.dataset\")\n",
    "print(f\"Loaded tokenized dataset with {len(dataset)} cells.\")\n",
    "\n",
    "dataset = dataset.add_column(\"label\", [0] * len(dataset))\n",
    "\n",
    "print(\"Loading fine-tuned Geneformer model...\")\n",
    "model = BertForSequenceClassification.from_pretrained(model_dir)\n",
    "\n",
    "trainer = Trainer(model=model, data_collator=DataCollatorForCellClassification())\n",
    "\n",
    "print(\"Making predictions with Geneformer...\")\n",
    "predictions = trainer.predict(dataset)\n",
    "print(\"Predictions complete.\")\n",
    "\n",
    "predicted_label_ids = np.argmax(predictions.predictions, axis=1)\n",
    "predicted_logits = [predictions.predictions[i][predicted_label_ids[i]] for i in range(len(predicted_label_ids))]\n",
    "predicted_labels = [label_mapping_dict[str(i)] for i in predicted_label_ids]\n",
    "\n",
    "adata.obs[\"predicted_cell_subclass\"] = predicted_labels\n",
    "adata.obs[\"predicted_cell_subclass_probability\"] = 1 / (1 + np.exp(-np.array(predicted_logits)))\n",
    "\n",
    "print(\"\\n--- Step 5: Standard Single-Cell Data Preprocessing and Analysis (Scanpy) ---\")\n",
    "\n",
    "sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "sc.pp.log1p(adata)\n",
    "sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5)\n",
    "\n",
    "if np.sum(adata.var['highly_variable']) > 0:\n",
    "    adata = adata[:, adata.var.highly_variable]\n",
    "    print(f\"Subsetted to {adata.shape[1]} highly variable genes.\")\n",
    "else:\n",
    "    print(\"No highly variable genes found with current parameters. Skipping subsetting.\")\n",
    "\n",
    "sc.pp.scale(adata, max_value=10)\n",
    "sc.tl.pca(adata, svd_solver=\"arpack\")\n",
    "sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40)\n",
    "sc.tl.umap(adata)\n",
    "\n",
    "print(\"Running Leiden clustering...\")\n",
    "sc.tl.leiden(adata)\n",
    "\n",
    "print(\"Scanpy preprocessing and dimensionality reduction complete.\")\n",
    "\n",
    "print(\"\\n--- Step 6: Visualize Results ---\")\n",
    "\n",
    "print(\"Generating UMAP plots...\")\n",
    "sc.pl.umap(adata, color=\"leiden\", title=\"Leiden Clustering of IMMUCan Data\", show=False, save=\"_leiden.png\")\n",
    "\n",
    "sc.pl.umap(\n",
    "    adata,\n",
    "    color=[\"predicted_cell_subclass_probability\", \"predicted_cell_subclass\"],\n",
    "    title=\"Predicted Geneformer Annotations for IMMUCan Data\",\n",
    "    show=False, save=\"_geneformer_predictions.png\"\n",
    ")\n",
    "\n",
    "sc.pl.umap(\n",
    "    adata,\n",
    "    color=[\"leiden\", \"predicted_cell_subclass\"],\n",
    "    legend_loc = 'on data',\n",
    "    title=\"Comparison: Leiden vs. Geneformer (IMMUCan Data)\",\n",
    "    show=True, save=\"_comparison.png\"\n",
    ")\n",
    "\n",
    "print(\"Analysis complete. UMAP plots saved as PNG files in your current directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import anndata as ad\n",
    "from scipy.io import mmread\n",
    "from pathlib import Path\n",
    "import re # For regular expressions to clean ENSEMBL IDs\n",
    "import os # For directory operations\n",
    "\n",
    "# --- Configuration ---\n",
    "# Define the path to your raw data directory\n",
    "# IMPORTANT: Replace '/projects/bioinformatics/DB/IMMUCan/data_raw' with your actual path\n",
    "raw_data_path = Path('/projects/bioinformatics/DB/IMMUCan/data_raw')\n",
    "\n",
    "# Define the output directory and file name for the prepared H5AD file\n",
    "h5ad_dir = \"./data/h5ad/\"\n",
    "output_file_name = \"pbmcs.h5ad\" # Using the name from your example\n",
    "output_file_path = Path(h5ad_dir) / output_file_name\n",
    "# --- End Configuration ---\n",
    "\n",
    "\n",
    "print(f\"Loading data from: {raw_data_path}\")\n",
    "\n",
    "# Load the data matrix\n",
    "try:\n",
    "    matrix = mmread(raw_data_path / 'matrix.mtx').tocsr()\n",
    "    print(\"Matrix shape:\", matrix.shape)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: matrix.mtx not found at {raw_data_path / 'matrix.mtx'}\")\n",
    "    exit()\n",
    "\n",
    "# Loading gene names and cell barcodes\n",
    "try:\n",
    "    # Assuming genes.tsv has two columns: [0] ENSEMBL ID with version, [1] Gene Symbol\n",
    "    genes = pd.read_csv(raw_data_path / 'genes.tsv', sep='\\t', header=None)\n",
    "    # Assuming barcodes.tsv has one column: [0] Cell Barcode\n",
    "    barcodes = pd.read_csv(raw_data_path / 'barcodes.tsv', sep='\\t', header=None)\n",
    "    print(f\"Loaded {len(genes)} genes and {len(barcodes)} barcodes.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading genes.tsv or barcodes.tsv: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- Data Preparation Steps ---\n",
    "\n",
    "# 1. Prepare 'var' (genes) DataFrame\n",
    "# Extract ENSEMBL gene ID without version number suffix for the primary index\n",
    "# Example: ENSG00000139618.12 -> ENSG00000139618\n",
    "# This will be the primary identifier for genes in the AnnData object's .var index\n",
    "cleaned_ensembl_ids = genes[0].apply(lambda x: re.sub(r'\\.\\d+$', '', x))\n",
    "\n",
    "# Create 'var_df' with the cleaned ENSEMBL IDs as the index\n",
    "var_df = pd.DataFrame(index=cleaned_ensembl_ids)\n",
    "var_df['gene_symbol'] = genes[1].values # Add gene symbol\n",
    "var_df['ensembl_id_full'] = genes[0].values # Store the full ENSEMBL ID for reference\n",
    "\n",
    "# Prepare 'obs' (barcodes/cells) DataFrame\n",
    "# Use cell barcode as index\n",
    "obs_df = pd.DataFrame(index=barcodes[0].values)\n",
    "\n",
    "# Create the AnnData object\n",
    "# The matrix should be cells x genes, so we transpose the loaded matrix.\n",
    "adata = ad.AnnData(X=matrix.transpose(), obs=obs_df, var=var_df)\n",
    "print(\"Initial AnnData object created with shape:\", adata.shape)\n",
    "\n",
    "# Set the name of the variable index (genes) to 'ensembl_id'\n",
    "# This is crucial as Geneformer often expects the index to be named 'ensembl_id'\n",
    "adata.var.index.name = 'ensembl_id'\n",
    "print(f\"Set adata.var.index.name to '{adata.var.index.name}'.\")\n",
    "\n",
    "\n",
    "# 2. Set the 'ensembl_id' column in adata.var\n",
    "# As per your requested format, set 'ensembl_id' column to the index of adata.var\n",
    "adata.var[\"ensembl_id\"] = adata.var.index\n",
    "print(f\"Set 'ensembl_id' column in adata.var. Example: {adata.var['ensembl_id'].head()}\")\n",
    "\n",
    "# 3. Add read counts to the obs column \"n_counts\"\n",
    "# Calculate the sum of counts for each cell (row sum of the transposed matrix)\n",
    "adata.obs[\"n_counts\"] = adata.X.sum(axis=1).A1 # .A1 converts sparse matrix row sums to a 1D numpy array\n",
    "print(f\"Added 'n_counts' to obs. Example counts: {adata.obs['n_counts'].head()}\")\n",
    "\n",
    "# 4. Add an ID column to be used for joining later in the obs column \"joinid\"\n",
    "# As per your requested format, use list(range(adata.n_obs))\n",
    "adata.obs[\"joinid\"] = list(range(adata.n_obs))\n",
    "print(f\"Added 'joinid' to obs. Example joinids: {adata.obs['joinid'].head()}\")\n",
    "\n",
    "\n",
    "print(\"\\n--- AnnData Object Summary ---\")\n",
    "print(adata)\n",
    "print(\"\\nFirst 5 rows of obs:\")\n",
    "print(adata.obs.head())\n",
    "print(\"\\nFirst 5 rows of var:\")\n",
    "print(adata.var.head())\n",
    "print(\"\\nColumns in adata.var before saving:\")\n",
    "print(adata.var.columns)\n",
    "\n",
    "\n",
    "# 5. Create the output directory if it doesn't exist\n",
    "print(f\"\\nChecking and creating output directory: {h5ad_dir}...\")\n",
    "if not os.path.exists(h5ad_dir):\n",
    "    os.makedirs(h5ad_dir)\n",
    "    print(f\"Created directory: {h5ad_dir}\")\n",
    "else:\n",
    "    print(f\"Directory already exists: {h5ad_dir}\")\n",
    "\n",
    "# 6. Write the resulting H5AD file to disk\n",
    "print(f\"\\nWriting prepared data to {output_file_path}...\")\n",
    "try:\n",
    "    # Attempt to remove the file if it exists to prevent 'file already open' errors\n",
    "    if os.path.exists(output_file_path):\n",
    "        print(f\"Removing existing file: {output_file_path}\")\n",
    "        os.remove(output_file_path)\n",
    "    adata.write(output_file_path)\n",
    "    print(\"Data preparation complete and file saved successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving H5AD file: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g6dDRxAKJOZ9"
   },
   "outputs": [],
   "source": [
    "token_dir = \"data/tokenized_data/\"\n",
    "\n",
    "if not os.path.exists(token_dir):\n",
    "    os.makedirs(token_dir)\n",
    "\n",
    "tokenizer = TranscriptomeTokenizer(custom_attr_name_dict={\"joinid\": \"joinid\"})\n",
    "tokenizer.tokenize_data(\n",
    "    data_directory=h5ad_dir,\n",
    "    output_directory=token_dir,\n",
    "    output_prefix=\"pbmc\",\n",
    "    file_format=\"h5ad\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EuZwVsE9JOZ9"
   },
   "source": [
    "### Preparing data from model\n",
    "\n",
    "Then let's fetch the mapping dictionary between Geneformer IDs and the associated cell subclass labels. This information is stored along the fine-tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0wcb4IH2JOZ9"
   },
   "outputs": [],
   "source": [
    "model_dir = \"./fine_tuned_geneformer/\"\n",
    "label_mapping_dict_file = os.path.join(model_dir, \"label_to_cell_subclass.json\")\n",
    "\n",
    "with open(label_mapping_dict_file) as fp:\n",
    "    label_mapping_dict = json.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LMYT0pycJOZ9"
   },
   "source": [
    "This dictionary contains all the possible cell labels available for the model, and the predictions on the section below will use these labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IkEnj9_dJOZ9"
   },
   "outputs": [],
   "source": [
    "for k in list(label_mapping_dict.keys())[:5]:\n",
    "    print(k, ': ', label_mapping_dict[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kbZsBXuLJOZ-"
   },
   "source": [
    "## Using the Geneformer fine-tuned model for cell subclass inference\n",
    "\n",
    "### Loading tokenized data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hYCqnR4QJOZ-"
   },
   "source": [
    "Let's load the tokenized test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ToLXgjH5JOZ-"
   },
   "outputs": [],
   "source": [
    "dataset = datasets.load_from_disk(token_dir + \"pbmc.dataset\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ecodHXcgJOZ-"
   },
   "source": [
    "We add a dummy cell metadata column `\"label\"` needed for Geneformer to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uCgnKoB3JOZ-"
   },
   "outputs": [],
   "source": [
    "dataset\n",
    "dataset = dataset.add_column(\"label\", [0] * len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h0_0TKB1JOZ-"
   },
   "source": [
    "### Performing inference of cell subclass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SLKiKmdyJOZ-"
   },
   "source": [
    "Now we can load the model and run the inference workflow.\n",
    "\n",
    "> ⚠️ Note, this step will be slow with CPUs, a machine with one GPU is recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MWSmcr86JOZ_"
   },
   "outputs": [],
   "source": [
    "# reload pretrained model\n",
    "model = BertForSequenceClassification.from_pretrained(model_dir)\n",
    "# create the trainer\n",
    "trainer = Trainer(model=model, data_collator=DataCollatorForCellClassification())\n",
    "# use trainer\n",
    "predictions = trainer.predict(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uf_d48_5JOZ_"
   },
   "source": [
    "And finally we select the most likely cell class based on the probability vector from the predictions of each cell in our test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OZkkCK9ZJOZ_"
   },
   "outputs": [],
   "source": [
    "predicted_label_ids = np.argmax(predictions.predictions, axis=1)\n",
    "predicted_logits = [predictions.predictions[i][predicted_label_ids[i]] for i in range(len(predicted_label_ids))]\n",
    "predicted_labels = [label_mapping_dict[str(i)] for i in predicted_label_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "glw9E1-RJOZ_"
   },
   "source": [
    "### Inspecting inference results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JKuxpJRVJOZ_"
   },
   "source": [
    "Then we add the prediction back to our loaded AnnData test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ia3etdnNJOZ_"
   },
   "outputs": [],
   "source": [
    "adata.obs[\"predicted_cell_subclass\"] = predicted_labels\n",
    "adata.obs[\"predicted_cell_subclass_probability\"] = np.exp(predicted_logits) / (1 + np.exp(predicted_logits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Z9z5gJZJOZ_"
   },
   "source": [
    "And it's ready for inspecting the predictions. Let's visualize the predictions on the UMAP space, the following is a basic processing workflow to derive a UMAP representation, of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vP4xw9MoJOZ_"
   },
   "outputs": [],
   "source": [
    "sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "sc.pp.log1p(adata)\n",
    "sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5)\n",
    "adata = adata[:, adata.var.highly_variable]\n",
    "sc.pp.scale(adata, max_value=10)\n",
    "sc.tl.pca(adata, svd_solver=\"arpack\")\n",
    "sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40)\n",
    "sc.tl.umap(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YIFAsl5CJOZ_"
   },
   "source": [
    "Let's also add the original cell type annotations as obtained in [Scapy's annotation tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html) of the same data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5OfM1F0QJOZ_"
   },
   "outputs": [],
   "source": [
    "sc.tl.leiden(adata)\n",
    "original_cell_types = [\n",
    "    \"CD4-positive, alpha-beta T cell (1)\",\n",
    "    \"CD4-positive, alpha-beta T cell (2)\",\n",
    "    \"CD14-positive, monocyte\",\n",
    "    \"B cell (1)\",\n",
    "    \"CD8-positive, alpha-beta T cell\",\n",
    "    \"FCGR3A-positive, monocyte\",\n",
    "    \"natural killer cell\",\n",
    "    \"dendritic cell\",\n",
    "    \"megakaryocyte\",\n",
    "    \"B cell (2)\",\n",
    "]\n",
    "adata.rename_categories(\"leiden\", original_cell_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_eSbWsEyJOZ_"
   },
   "source": [
    "These are the original annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8HfLgvrAJOaA"
   },
   "outputs": [],
   "source": [
    "sc.pl.umap(adata, color=\"leiden\", title=\"Original Annotations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cXs4qjwiJOaA"
   },
   "source": [
    "And these are the predicted annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6PRUAL7AJOaA"
   },
   "outputs": [],
   "source": [
    "sc.pl.umap(\n",
    "    adata,\n",
    "    color=[\"predicted_cell_subclass_probability\", \"predicted_cell_subclass\"],\n",
    "    title=\"Predicted Geneformer Annotations\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(\n",
    "    adata,\n",
    "    color=[\"leiden\", \"predicted_cell_subclass\"],\n",
    "    legend_loc = 'on data'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DswC_anSJOaA"
   },
   "source": [
    "## Using the Geneformer fine-tuned model for data projection\n",
    "\n",
    "### Generating Geneformer embeddings for 10X PBMC 3K data\n",
    "\n",
    "To project new data, for example the 10X PBMC 3K data, into the Census embedding space from Geneformer's fine-tune model, we can use `EmbExtractor` from the [Geneformer](https://huggingface.co/ctheodoris/Geneformer) package as follows.\n",
    "\n",
    "We first need to get the number of categories (cell subclasses) present in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9kXVvjITJOaA"
   },
   "outputs": [],
   "source": [
    "n_classes = len(label_mapping_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SPPIJhnJJOaA"
   },
   "source": [
    "Then we can run the `EmbExtractor`, which randomize the cells during the process and thus we keep track of `\"joinid\"`.\n",
    "\n",
    "> ⚠️ Note, this step will be slow with CPUs, a machine with one GPU is recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mWt56OitJOaB"
   },
   "outputs": [],
   "source": [
    "output_dir = \"data/geneformer_embeddings\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "embex = EmbExtractor(\n",
    "    model_type=\"CellClassifier\",\n",
    "    num_classes=n_classes,\n",
    "    max_ncells=None,\n",
    "    emb_label=[\"joinid\"],\n",
    "    emb_layer=0,\n",
    "    forward_batch_size=30,\n",
    "    nproc=8,\n",
    ")\n",
    "\n",
    "embs = embex.extract_embs(\n",
    "    model_directory=model_dir,\n",
    "    input_data_file=token_dir + \"pbmc.dataset\",\n",
    "    output_directory=output_dir,\n",
    "    output_prefix=\"emb\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls data/geneformer_embeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "18jsyOW7JOaB"
   },
   "source": [
    "Then we simply re-order the embeddings based on `\"joinid\"` and then merge them to the original AnnData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "byB38Z4pJOaB"
   },
   "outputs": [],
   "source": [
    "embs = embs.sort_values(\"joinid\")\n",
    "adata.obsm[\"geneformer\"] = embs.drop(columns=\"joinid\").to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qTizH2g4JOaB"
   },
   "source": [
    "Let's take a look at these Geneformer embeddings in a UMAP representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T2LOhPXmJOaB"
   },
   "outputs": [],
   "source": [
    "sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, use_rep=\"geneformer\")\n",
    "sc.tl.umap(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vjmWqd_nJOaC"
   },
   "outputs": [],
   "source": [
    "sc.pl.umap(adata, color=\"predicted_cell_subclass\", title=\"10X PBMC 3K in Geneformer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gXEc-u6CJOaC"
   },
   "source": [
    "### Joining Geneformer embeddings from 10X PBMC 3K data with other Census datasets\n",
    "\n",
    "There are multiple datasets in Census from PBMCs, and all human Census data has pre-calculated Geneformer embeddings, so now we can join the embeddings we generated above from the 10X PBMC 3K dataset with Census data.\n",
    "\n",
    "Let's grab a few PBMC datasets from Census and request the Geneformer embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cellxgene_census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hcpicfRcJOaC"
   },
   "outputs": [],
   "source": [
    "# Some PBMC data from these collections\n",
    "# 1. https://cellxgene.cziscience.com/collections/c697eaaf-a3be-4251-b036-5f9052179e70\n",
    "# 2. https://cellxgene.cziscience.com/collections/f2a488bf-782f-4c20-a8e5-cb34d48c1f7e\n",
    "\n",
    "dataset_ids = [\n",
    "    \"fa8605cf-f27e-44af-ac2a-476bee4410d3\",\n",
    "    \"3c75a463-6a87-4132-83a8-c3002624394d\",\n",
    "]\n",
    "\n",
    "with cellxgene_census.open_soma(census_version=\"2023-12-15\") as census:\n",
    "\n",
    "    adata_census = cellxgene_census.get_anndata(\n",
    "        census=census,\n",
    "        measurement_name=\"RNA\",\n",
    "        organism=\"Homo sapiens\",\n",
    "        obs_value_filter=f\"dataset_id in {dataset_ids}\",\n",
    "        obs_embeddings=[\"geneformer\"],\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FEz-mRi2JOaC"
   },
   "source": [
    "To simplify let's select the genes that are also present in the 10X PBMC 3K dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xQ_X_UkNJOaC"
   },
   "outputs": [],
   "source": [
    "adata_census.var_names = adata_census.var[\"feature_id\"]\n",
    "shared_genes = list(set(adata.var_names) & set(adata_census.var_names))\n",
    "adata_census = adata_census[:, shared_genes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gviix6NNJOaD"
   },
   "source": [
    "And take a subset of these cells, let's take 3K cells to match the size of the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s02zaJZSJOaD"
   },
   "outputs": [],
   "source": [
    "index_subset = np.random.choice(adata_census.n_obs, size=3000, replace=False)\n",
    "adata_census = adata_census[index_subset, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4cPzoNbTJOaD"
   },
   "source": [
    "Now we can join these Census data to the 10X PBMC 3K data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RNSvCRdWJOaD"
   },
   "outputs": [],
   "source": [
    "adata_census.obs[\"dataset\"] = \"Census - \" + adata_census.obs[\"dataset_id\"].astype(str)\n",
    "adata.obs[\"dataset\"] = \"10X PBMC 3K\"\n",
    "adata.obs[\"cell_type\"] = \"Predicted - \" + adata.obs[\"predicted_cell_subclass\"].astype(str)\n",
    "\n",
    "adata_joined = sc.concat([adata, adata_census], join=\"outer\", label=\"batch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nk5z6_NrJOaD"
   },
   "source": [
    "Let's now inspect all of the cells in the UMAP space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ftLOPd7tJOaD"
   },
   "outputs": [],
   "source": [
    "sc.pp.neighbors(adata_joined, n_neighbors=10, n_pcs=40, use_rep=\"geneformer\")\n",
    "sc.tl.umap(adata_joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sMhMQPl-JOaD"
   },
   "outputs": [],
   "source": [
    "sc.pl.umap(adata_joined, color=\"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iGw2hO_XJOaE"
   },
   "outputs": [],
   "source": [
    "sc.pl.umap(adata_joined, color=\"cell_type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SiX-TSqw45Q0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geneformer_shared",
   "language": "python",
   "name": "geneformer_shared"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
